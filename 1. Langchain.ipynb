{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94f54b6",
   "metadata": {},
   "source": [
    "### Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540ce32",
   "metadata": {},
   "source": [
    "**LangChain** is a framework for developing applications powered by language models. Applications will not only call out to a language model, but will also be:\n",
    "\n",
    "Data-aware: connect a language model to other sources of data\n",
    "\n",
    "Agentic: allow a language model to interact with its environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d03ed98",
   "metadata": {},
   "source": [
    "#### Models \n",
    "\n",
    "Models which are used in Langchain\n",
    "- LLMs: Large language models takes string as input and string as output\n",
    "- Chat Models: These are language models with API these models take string as input anf return chat message.\n",
    "- Text Embedding Models: These models takes string input and returns vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "961bd170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52b9c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a96d5",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2341309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d90c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(\"./config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb1b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    model = 'text-davinci-003', \n",
    "    openai_api_key=config[\"openai_api_key\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2c1844",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.predict(\"Hello how are you\")\n",
    "# Hi there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe84f5",
   "metadata": {},
   "source": [
    "Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "004ef698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4070597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(openai_api_key=config[\"openai_api_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fb74543",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model.predict(\"Hi\")\n",
    "# Hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9340a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0c6366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.predict_messages([HumanMessage(content=\"Hi\")])\n",
    "# AIMessage(content='\\n\\nHello! Nice to meet you!', additional_kwargs={}, example=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9de922c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model.predict_messages([HumanMessage(content=\"say hi!\")])\n",
    "# AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, example=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb522e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0a056c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(\"Hello how are you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf066af",
   "metadata": {},
   "source": [
    "Text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d146c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c2d0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=config[\"openai_api_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3449e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a test document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "967c9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713f6f7",
   "metadata": {},
   "source": [
    "#### Prompts\n",
    "\n",
    "A prompt is the value passed into the Language Model. This value can either be a string (for LLMs) or a list of messages (for Chat Models).\n",
    "\n",
    "- A standard interface for string prompts and message prompts\n",
    "- A standard (to get started) interface for string prompt templates and message prompt templates\n",
    "- Example Selectors: methods for inserting examples into the prompt for the language model to follow\n",
    "- OutputParsers: methods for inserting instructions into the prompt as the format in which the language model should output information, as well as methods for then parsing that string output into a format.\n",
    "\n",
    "\n",
    "**PromptTemplates** are responsible for constructing a prompt value. These PromptTemplates can do things like formatting, example selection, and more. At a high level, these are basically objects that expose a format_prompt method for constructing a prompt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafde705",
   "metadata": {},
   "source": [
    "Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d274e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bfb8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_prompt = PromptTemplate.from_template(\"Tell me something about {subject}\")\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"Tell me something about {subject}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d7c766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_prompt_value = string_prompt.format_prompt(subject = \"science\")\n",
    "chat_prompt_value = chat_prompt.format_prompt(subject = \"science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7590ca76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me something about science'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_prompt_value.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d7ceb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Tell me something about science'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_value.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2705a575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me something about science', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_prompt_value.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9da290c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me something about science', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_value.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eeaad4",
   "metadata": {},
   "source": [
    "Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b85e8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b051efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "I want you to act as a naming consultant for new companies.\n",
    "What is a good name for a company that makes {product}?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "395bb1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI want you to act as a naming consultant for new companies.\\nWhat is a good name for a company that makes mobiles?\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=template\n",
    ")\n",
    "prompt.format(product = \"mobiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0270b067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"How are you\")\n",
    "no_input_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e5fba1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a Adam joke about Mark.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_input_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"],\n",
    "    template = \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "multi_input_prompt.format(adjective = \"Adam\", content = \"Mark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7203b1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adjective', 'content']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Tell me a {adjective} joke about {content}.\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cedf0690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")\n",
    "# -> Tell me a funny joke about chickens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0be24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
